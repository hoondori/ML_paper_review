{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Genenrative model by conditionals\n",
    "\n",
    "## Image Generative Model\n",
    "- 이미지를 생성할 수 있는 확률 모델링, p(x)를 구하고 싶다. \n",
    "- 되기만 한다면 다양한 활용 가능\n",
    " - image compression, image denoising, debluring, high resolution\n",
    "- 근데 어렵다. \n",
    " - 매우 고차원, \n",
    "   - p(x) : joint dist over 320*320 \n",
    " - 매우 구조적\n",
    "- 기존 접근 \n",
    " - variation autoencoder 접근, but intracable 문제를 대처하기 위해 approximate inference 사용할 수 밖에 없다.\n",
    " \n",
    "### SK-T brain의 Generative Model 101\n",
    " - [https://www.facebook.com/SKTBrain/posts/313726382331516](https://www.facebook.com/SKTBrain/posts/313726382331516)\n",
    "\n",
    "## 좋은 Image generative model의 조건\n",
    "- Expressive \n",
    "- ** Tractible **\n",
    "- Scalable\n",
    "\n",
    "## 오늘의 접근 방법 : factorization into conditionals\n",
    "- joint를 conditionals 표현함으로서 tractible 하게 된다. => PGM의 접근\n",
    "- p(x1,x2,x3) = p(x1) * p(x2|x1) * p(x3|x2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 번외 : RNN 변형 (방향성, 차원성, 계층성)\n",
    "[http://www.slideshare.net/grigorysapunov/multidimensional-rnn](http://www.slideshare.net/grigorysapunov/multidimensional-rnn)\n",
    "\n",
    "## 기본형 with LSTM\n",
    "\n",
    "![](./images/pixelcnn/01.png)\n",
    "\n",
    "## 방향성 변형\n",
    "\n",
    "![](./images/pixelcnn/02.png)\n",
    "\n",
    "## 차원 변형 (1-dim-> multi-dim)\n",
    "- 기존 1-d만, 고차원 데이터(ex. images)에 부적합한 측면\n",
    "- data에 ordering이 있는 것을 가정\n",
    "\n",
    "![](./images/pixelcnn/03.png)\n",
    "![](./images/pixelcnn/04.png)\n",
    "\n",
    "## 방향성 + 차원 변형\n",
    "- 다중 방향성, 다중 차원 \n",
    "- 예시에서는 4방향, 2차원 \n",
    "\n",
    "![](./images/pixelcnn/05.png)\n",
    "\n",
    "## 계층성 (Hierachical subsampling RNN )\n",
    "\n",
    "![](./images/pixelcnn/06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 첫번째 논문: Generative Image Modeling Using Spatial LSTMs\n",
    "- [https://arxiv.org/abs/1506.03478](https://arxiv.org/abs/1506.03478)\n",
    "\n",
    "\n",
    "## p(x) as factorized conditionals\n",
    "- next pixel의 확률을 그 이전(위에서부터 행 by 행, 같은 행에서는 바로 그 pixel 직전까지) 것들에 종속되서 결정\n",
    "\n",
    "![](./images/pixelcnn/07.png)\n",
    "\n",
    "![](./images/pixelcnn/08.png)\n",
    "\n",
    "## p(xi) as gaussian mixture models\n",
    "- 각 p(xi)는 다양한 covariance matrix를 mixture로 묶은 모델\n",
    "\n",
    "![](./images/pixelcnn/09.png)\n",
    "\n",
    "## 현실적으로는 causal neighbor에만 종속되게\n",
    "- next pixel의 그 이전 pixel을 모두 고려하면 너무 계산량과 parameter가 폭주\n",
    "- markov 가정을 고려해서 최근 것만 고려\n",
    " - 삼각형 이웃 : 최근의 행, 최근의 열\n",
    " \n",
    "\n",
    "## 2-D LSTM 을 deep하게 쌓은 학습 모델 구성\n",
    "- 이러한 조건부 확률 분포들을 deep neural network를 통해 자동으로 학습하도록 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 두번째 논문 : Pixel Recurrent Neural Networks\n",
    "- [https://arxiv.org/abs/1601.06759](https://arxiv.org/abs/1601.06759)\n",
    "\n",
    "\n",
    "## 첫번째와 대동 소이 \n",
    "- joint dist 을 조건부 확률 분포의 곱으로 표현 \n",
    "- multi-dim LSTM 사용\n",
    "\n",
    "## 개선점\n",
    "- RGB 이미지로 확장 : R,G,B 끼리도 conditioning\n",
    "- pdf 가 아닌 pmf : 256 value\n",
    "- 12-depth 2-D LSTM\n",
    "- 2방향 2-D LSTM\n",
    "\n",
    "\n",
    "## RGB conditioning\n",
    "\n",
    "![](./images/pixelcnn/10.png)\n",
    "![](./images/pixelcnn/11.png)\n",
    "\n",
    "## 256-value multinomial pmf\n",
    "\n",
    "![](./images/pixelcnn/12.png)\n",
    "\n",
    "## PixelRNN #1 : Row LSTM\n",
    "- unidirectional\n",
    "- 삼각형의 causal neighborhood\n",
    "\n",
    "## PixelRNN #2 : Bidirectional 2-D LSTM\n",
    "\n",
    "![](./images/pixelcnn/13.png)\n",
    "\n",
    "## PixelRNN #3 : Multi-Scale 버젼\n",
    "- 한 개의 subsampled pixelRNN\n",
    "- 그 위에 여러 개의 up-sampled pixelRNN 쌓기\n",
    "- 참고) deconv in CNN\n",
    "\n",
    "![](./images/pixelcnn/14.png)\n",
    "\n",
    "## 실험\n",
    "\n",
    "![](./images/pixelcnn/15.png)\n",
    "![](./images/pixelcnn/16.png)\n",
    "![](./images/pixelcnn/17.png)\n",
    "\n",
    "## 구현 : TensorFlow implementation of Pixel Recurrent Neural Networks\n",
    "[https://github.com/carpedm20/pixel-rnn-tensorflow](https://github.com/carpedm20/pixel-rnn-tensorflow)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번외 : LSTM에서 착안한 gating 기법을 이용한 심층 네트워크 학습\n",
    "- [https://arxiv.org/pdf/1507.06228v2.pdf](https://arxiv.org/pdf/1507.06228v2.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 세번째 논문 :Conditional Image Generation with PixelCNN Decoder\n",
    "- [https://arxiv.org/abs/1606.05328](https://arxiv.org/abs/1606.05328)\n",
    "\n",
    "\n",
    "## PixcelCNN\n",
    "- Input: N x N x 3 \n",
    "- Output : N x N x 3 x 256\n",
    "- Filter : 5 x 5 with mask\n",
    "\n",
    "## Gated Convolutional Layers\n",
    "- PixelRNN의 장점 분석\n",
    " - 각 층(layer)에서 previous pixel과의 풍부한 interaction이 있다. \n",
    " - LSTM에서 multiplicative unit이 있다. => 비선형성? 좀 더 풍부한 복잡도(complexity)를 유발\n",
    "- PixcelRNN에서 이러한 특징을 받아들이게 고치면\n",
    " - 층을 깊게 쌓자. 그러면 convolution의 특징상 층이 깊어지면 좀 더 많은 previous pixel과 interaction이 강해진다.\n",
    " - 기존 relu를 gated activation unit으로 바꾸어서 더 풍부한 복잡도를 갖게 하자.\n",
    " \n",
    "![](./images/pixelcnn/19.png)\n",
    "\n",
    "![](./images/pixelcnn/20.png)\n",
    "\n",
    "\n",
    "## Conditional PixelCNN: 추가적인 정보에 dependent한 모델\n",
    "- 외부에서 추가적인 정보를 제공할 때 generative model\n",
    " - ex) class label in CIFAR-10\n",
    "\n",
    "![](./images/pixelcnn/18.png)\n",
    "\n",
    "- additive 한 속성으로 보고,  y = Wx + Vh 처럼 모델링\n",
    "\n",
    "![](./images/pixelcnn/21.png)\n",
    "- 예를 들어 h가 class label 에 대한 one-hot encoding이라면 이는 마치 각 레이어별로 특정 클래스에 대한 선호(bias)가 있는 상황이 되는 것이다.\n",
    "- 위의 식은 pixel location에 dependent하지 않다.\n",
    " - 왜냐하면 이미지의 어디에 대한 정보가 아니라 무엇에 대한 정보이기 때문이다.\n",
    "- 이를 변형해서 위치 정보와 함께 제공할 수도 있다.\n",
    " - 이러면 특정 위치에서 유효한 정보를 주는 셈\n",
    "\n",
    "\n",
    "\n",
    "## blind spot in receptive field\n",
    "[TODO]\n",
    "\n",
    "\n",
    "## PixelCNN AutoEncoder\n",
    "[TODO]\n",
    "\n",
    "\n",
    "## 실험\n",
    "\n",
    "![](./images/pixelcnn/22.png)\n",
    "![](./images/pixelcnn/23.png)\n",
    "![](./images/pixelcnn/24.png)\n",
    "![](./images/pixelcnn/25.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
