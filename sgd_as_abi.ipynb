{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradident Descent as Approxiate Baysian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  요약 \n",
    "\n",
    "* 일정한 학습율을 갖는 SGD는 stationary distribution의 Markov chain을 시뮬레이션한다.\n",
    "* 이러한 constant SGD를 approximate Baysian posterior inference 로 활용할 수 있다. \n",
    "* constant SGD는 hyperparameter를 최적화하는 variational EM으로 활용할 수 있다. \n",
    "* 기타..\n",
    "\n",
    "\n",
    "## 수많은 키워드/사전지식..\n",
    "\n",
    "* SGD variant\n",
    "  * decreasing step size\n",
    "  * constant step size\n",
    "  * momemtum-based\n",
    "  * dense/sparse preconditioner \n",
    "* MCMC variant\n",
    "  * vanilla \n",
    "    * Metropolis-Hastings\n",
    "  * stochastic gradient based\n",
    "    * SG Langevin dynamics\n",
    "    * SG Hamiltonian MC\n",
    "    * SG Fisher scoring\n",
    "* various dynamics and stochastic process\n",
    "  * Langevin dynamics\n",
    "  * Hamiltonian dynamics\n",
    "  * Ornstein-Uhlenbeck process\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of MCMC \n",
    "\n",
    "### Gibbs dist, Metropolis-Hastings, Hamiltonian MCMC\n",
    "\n",
    "* http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html\n",
    "\n",
    "### Stochastic Gradient Langevin MCMC\n",
    "\n",
    "* https://www.slideshare.net/Scyfer/deep-generative-learningicmlpart1-36627518\n",
    "* https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf\n",
    "\n",
    "\n",
    "### Stochastic Gradient Fisher Scoring\n",
    "\n",
    "* https://www.slideshare.net/Scyfer/deep-generative-learningicmlpart2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "\n",
    "![](./images/sgd/01.png)\n",
    "\n",
    "* Batch Gradient\n",
    "\n",
    "![](./images/sgd/02.png)\n",
    "\n",
    "\n",
    "* Stochastic Gradient\n",
    "\n",
    "![](./images/sgd/03.png)\n",
    "![](./images/sgd/04.png)\n",
    "\n",
    "* SG with momentum\n",
    "  * http://ruder.io/optimizing-gradient-descent/index.html#momentum\n",
    "  \n",
    "* SG with preconditioner\n",
    "  * 공간을 transform 해서 보다 빠르게 수렴할 수 있게 할수 있다면 ...\n",
    "  * http://www.alglib.net/optimization/preconditioning.php\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4가지 가정을 통해 Ornstein-Uhlenbeck Process로 간주 \n",
    "\n",
    "* 위의 업데이트식은 discreate-time인 경우이다. \n",
    "* continous-time에서는 어떤 과정으로 이해할 수 있나?\n",
    "\n",
    "\n",
    "### 3-phase model\n",
    "\n",
    "* search phase - local minima를 찾아 헤매는 단계\n",
    "* vicinity in local minima - 근방에 도착\n",
    "* around local minima - local minima 의 stationary dist에서 일종의 sampling하는 모습\n",
    "\n",
    "\n",
    "### 가정들\n",
    "\n",
    "* 가정 1\n",
    "  * SG gradient의 noise가 있을텐데 이것이 가우스 분포를 띈다고 가정\n",
    "    \n",
    "\n",
    "![](./images/sgd/05.png)\n",
    "\n",
    "* 가정 2 \n",
    "  * 위의 noise 분포의 Covariance Matrix는 모델 파라미터와 무관하다고 하자. 그리고 symmetric PSD로 가정하면 factorization 된다. \n",
    "    * into Lower traiangle matrix mulitply by its transpose\n",
    "    * https://en.wikipedia.org/wiki/Cholesky_decomposition\n",
    "    \n",
    "![](./images/sgd/06.png)\n",
    "\n",
    "* 가정 3\n",
    "  * discrete-time 기반의 eqns을 continuous-time 기반으로 근사화할 수 있다. \n",
    "  \n",
    "![](./images/sgd/07.png)  \n",
    "    \n",
    "    \n",
    "* 가정 4 \n",
    "  * deep local minima 근방으로 가서, SGD의 iteration시의 statitionary dist 상에서는 loss function은 quadratic 형태가 된다.\n",
    "\n",
    "![](./images/sgd/08.png) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD as Ornstein-Uhlenbeck Process\n",
    "\n",
    "* OU process\n",
    "  * i.e Gaussian-Markov Process\n",
    "  * browian motion of massive molecules\n",
    "  * stationary dist 이 gaussian으로 간단하게 된다. \n",
    "  \n",
    "![](./images/sgd/11.png)\n",
    "![](./images/sgd/09.png) \n",
    "![](./images/sgd/10.png) \n",
    "\n",
    "* stationary dist의 covariance는 \n",
    "  * learning rate에 비례 => 학습률을 크게 하면 반동이 커짐\n",
    "  * A에 반비례\n",
    "  * minibatch 사이즈에 반비례 => 큰 배치를 하면 반동이 작아짐\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD as Approximate Inference\n",
    "\n",
    "\n",
    "* problem setup\n",
    "\n",
    "![](./images/sgd/12.png) \n",
    "\n",
    "![](./images/sgd/13.png) \n",
    "\n",
    "* 전형적인 SGD as optimization은 위에처럼 loss를 minimize하는 MAP 를 찾는 것 (point-estimate)\n",
    "\n",
    "* 여기서는 오히려 SGD의 parameter들을 튜닝해서 SGD 를 baysian posterior sampling에 써먹을 수 있음을 보인다. \n",
    "  * parameter : learning rate, preconditioner, mini-batch size etc\n",
    "\n",
    "* 아래처럼 constant SGD는 true posterior를 swing-by하면서 sampling을 할 수 있다.\n",
    "\n",
    "![](./images/sgd/14.png) \n",
    "\n",
    "* posterior local minima 주변에서 형성된 stationary distribution은 gaussian일 거라 가정하고 \n",
    "  * 앞서 정의한 OU process의 stationrary distribution과의 KL divergence를 최소화하는 파라미터들을 찾으면 된다. \n",
    "\n",
    "![](./images/sgd/15.png)\n",
    "![](./images/sgd/16.png)\n",
    "![](./images/sgd/17.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
