{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLNet : Learning a URL Representation with Deep Learning for Malicious URL Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Previous Methods\n",
    "\n",
    "##### blacklist, whitelist\n",
    "- cannot be exhaustive, cannot detect newly generated malicilous URLs\n",
    "\n",
    "##### by machine learning\n",
    "- Bag-of-Words like features, with SVM\n",
    "- inable to capture semantic and sequential patterns\n",
    "- require substantial manual feature engineering\n",
    "- inable to handle unseen features and generalize to test data\n",
    "\n",
    "###  Our method\n",
    "- Deep learning with CNN\n",
    "  - learn to classify\n",
    "  - learn word/char embedding jointly\n",
    "  - advanced word-embedding to solve too many rare words problem\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malicious URL detection\n",
    "\n",
    "### Problem setting\n",
    "![](./images/urlnet/01.png)\n",
    "\n",
    "\n",
    "### Lexical Features\n",
    "\n",
    "- URL splitted into words which are delimited by special characters\n",
    "- dictionary constructed by unique words in tranining set\n",
    "- features\n",
    "  - Bag-of-Words features : occurance in dictionary list\n",
    "  - length of URL, lengths of different segments in URL, number of dots\n",
    "  - lack of sequential info => create a seperate dict for every segments of the URL\n",
    "![](./images/urlnet/07.png)\n",
    "\n",
    "- inable to obtain information from rare words\n",
    "  - most of words appears only once \n",
    "  - in training => become unknown\n",
    "  - in test => become unknown\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLNet\n",
    "\n",
    "### embedding \n",
    "\n",
    "![](./images/urlnet/02.png)\n",
    "\n",
    "\n",
    "### CNN convolution\n",
    "\n",
    "![](./images/urlnet/03.png)\n",
    "\n",
    "\n",
    "### CHAR embedding and Detection\n",
    "\n",
    "- but limitations : ignore word boundary, weak to attak of minor modification \n",
    "![](./images/urlnet/04.png)\n",
    "\n",
    "### Word-level embedding and Detection\n",
    "\n",
    "![](./images/urlnet/05.png)\n",
    "\n",
    "#### Improved Word Embedding Using Character-level Word Embedding\\\n",
    "\n",
    "![](./images/urlnet/06.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "![](./images/urlnet/08.png)\n",
    "![](./images/urlnet/09.png)\n",
    "![](./images/urlnet/10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
