{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL PREDICTIVE BELIEF REPRESENTATIONS, DeepMind, 2018\n",
    "\n",
    "## 요약 \n",
    "\n",
    "* 부분 관측만 가능한 환경(ex. POMDP)에서 비지도학습을 통해서 환경에 대한 좋은 잠재 표현을 구하는 문제\n",
    "* 좋은 잠재 표현(representation)이란 belief state를 잘 encoding해야 하는 것\n",
    "* 우리는 딥러닝 모델을 통해서 이러한 belief representation을 구하는 것을 제안\n",
    "* 좋은 표현을 얻기 위해서 one-step-prediction 기제와 CPC(constrastive predictive coding) 기반 multi-step prediction 기제를 사용\n",
    "* 결론적으로 action-dependent CPC multi-step prediction이 매우 복잡한 환경에 대한 잠재 표현을 찾는 데에 효과적이었다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도입 \n",
    "\n",
    "### 비지도학습 기반 표현학습(representation learning)\n",
    "\n",
    "* 목표는 가능한 유용한 정보를 인코딩해서 이를 바탕으로 다양한 tasks를 풀 수 있는 토양을 만드는 것\n",
    "* 표현 학습은 특히 부분 관측 환경(ex. navigation task with first-person view)에서 중요\n",
    "  * 환경을 부분적으로만 보거나 noisy한 관측을 하는 경우 \n",
    "* 이러한 환경에서는 에이전트는 해당 환경의 상태에 대한 불확실성을 충분히 반영한 믿음 상태(belief state)를 구축하는 것이 중요\n",
    "* 이러한 belief state는 미래 상태 예측이나 미래 관측 예측을 가능케 하는 충분 통계(sufficient statistic)이다. \n",
    "\n",
    "### 표현학습의 quality 평가 \n",
    "\n",
    "* black-box approach\n",
    "  * 배운 상태 표현의 퀄러티를 특정 supervised/RL task의 성능으로 간접적으로 측정\n",
    "* 우리는 glass-box approach를 제안 \n",
    "  * 배운 표현으로 직접적으로 ground-truth 환경 상태를 예측하고, 이를 통해 직접적으로 표현 학습의 퀄러티를 측정\n",
    "\n",
    "### 표현학습의 방법들\n",
    "\n",
    "* one-step frame prediction\n",
    "  * 바로 다음 frame의 장면(observation)을 예측 \n",
    "* constrastive prediction coding(CPC, Ooord, 2018)\n",
    "  * true next sequence인지 fake next sequence인지를 판가름(GAN 접근법)\n",
    "* CPC|Action\n",
    "  * 위에 방법에서 action 정보를 추가로 입력으로 주는 경우 \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partially Observable Markov Decision Process (POMDP, Lovejoy, 1991)\n",
    "\n",
    "![](./images/beliefref/01.png)\n",
    "\n",
    "![](./images/beliefref/02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Contrastive estimation (NCE, Gutmann, 2010)\n",
    "\n",
    "* positive 데이터 분포에서 온 샘플과 negative 데이터 분포에서 온 샘플을 차별화(discriminate)하는 방향으로 학습하는 방법 \n",
    "  * ex) GAN에서는 true와 fake dist 구분\n",
    "  * ex) BERT에서는 true next sentence와 fake next scentence 구분\n",
    "  * 여기서는 true next sequence of observation과 fake next sequence of observation 구분\n",
    "\n",
    "* 학습 목표 수립과 optimal solution\n",
    "\n",
    "![](./images/beliefref/03.png)\n",
    "![](./images/beliefref/04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연관 연구들\n",
    "\n",
    "* POMDP 환경에서의 compact한 belief representaion만 확보하면 이어지는 RL task에서 더 우수한 성능을 낼 수 있다. \n",
    "  * Guestrin 2003, ...\n",
    "* Predictive State Representation(PSR, Littman 2002)에서는\n",
    "  * 현재까지의 action들로부터 미래의 observation 시퀀스를 예측을 하는 테스트를 해서 좋은 표현 학습 여부를 가렸다.\n",
    "  * 우리는 이를 거꾸로 활용해서, 미래 관측 예측을 하게끔 학습해서 좋은 표현 학습을 얻고자 한다. \n",
    "* 또다른 연구자들은 지도학습을 통해서 좋은 잠재 표현을 얻고자 했다 \n",
    "  * 우리는 비지도학습\n",
    "* 또다른 연구자들은 직접적으로 POMDP의 state transition model을 추정하려고 했다. \n",
    "  * 우리는 directly가 아니라 implicitly하게..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture and Algorittm\n",
    "\n",
    "* PSR에 착안해서 미래 관측을 예측하는 것, \n",
    "* direct하게 미래 관측을 예측하기 보다는 CPC접근으로 true 관측열과 false 관측열을 구분하는 것으로 대처\n",
    "* CPC|action architecture\n",
    "  * Blue GRU를 사용해서 이때까지의 관측열과 행동열을 encoding해서 current belief 형성\n",
    "  * current belief는 action GRU(red)를 initialize 하는 데 사용\n",
    "  * action-GRU는 true 미래 행동열과 결합하여 true/fake 미래 관측열 분간 task를 풀게 한다. \n",
    "![](./images/beliefref/05.png)\n",
    "\n",
    "* one-step frame prediction (Bengio, 2007)\n",
    "  * current belief와 current action을 바탕으로 one-step 미래 관측 1개를 예측하는 것 \n",
    "  \n",
    "* 학습\n",
    "  * mini-batch 내에서 uniformly하게 negative example 뽑아도 잘 동작 \n",
    "  * positive와 negative의 비율은 less significant하다.\n",
    "    * 아래에서는 positive 1건 보여주고, negative 1건 보여주고, 같은 비중으로...\n",
    "\n",
    "![](./images/beliefref/06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험\n",
    "\n",
    "### Toy GridWorld\n",
    "\n",
    "* small grid를 전진/후진/방향틈의 동작으로 돌아다님, 행동은 랜덤으로 택하되, 한번 한 행동은 1-5회 사이에서 반복\n",
    "* 현 위치에서 5-length만큼만 관측(POMDP)\n",
    "* 학습한 표현의 평가를 위해서, 별도의 classifier를 학습하여, 주어진 잠재 표현을 바탕으로 에이전트의 위치와 방향을 예측하게 함\n",
    "\n",
    "* 아래 그림을 보면 \n",
    "  * 부분 관측의 한계로 인해 에이전트의 위치와 방향에 대한 예측의 불확실성이 잘 표현되어 있다. \n",
    "  * 하지만 벽과 같은 결정적인 증거 관측을 통해서 불확실성이 급격히 감소되고 있음을 알 수 있다. \n",
    "  * 간접적으로 belief representation이 잘 되있다고 말할 수 있겠다. \n",
    "![](./images/beliefref/07.png)\n",
    "\n",
    "### Deepmind platform 제공 4가지 환경 \n",
    "\n",
    "* fixed : single room, object 위치 고정\n",
    "* room : single room, object randomized\n",
    "* maze : fixed maze, object randomized\n",
    "* terreain : natural desert and forest feature and objects\n",
    "\n",
    "![](./images/beliefref/08.png)\n",
    "\n",
    "### 알고리즘별 비교\n",
    "\n",
    "* 더 먼 CPC 미래 관측열 예측이 더 낫다. \n",
    "  * CPC 30 > CPC 1\n",
    "  * CPC|Action 30 > CPC|Action 1\n",
    "  * 그렇다고 multi-step FP를 하는 것은 너무 많은 computtion cost가 들 것이다. \n",
    "* 심플환 환경에서는 FP가 동작을 꽤 하지만, terrain처럼 복잡한 환경에 되면 관측 자체를 예측하는 것이 매우 challengin하게 되므롤 CPC 기반이 FP보다 우수하게 된다. \n",
    "* 그냥 CPC보다는 CPC|Action이 더 낫다\n",
    "\n",
    "![](./images/beliefref/09.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 싷험\n",
    "\n",
    "### INCREASED OBJECT INTERACTION\n",
    "\n",
    "* 물체 위치가 고정된 fixed에서는 물체 위치가 랜덤한 room이나 maze에 비해서 물체 위치 예측이 더 잘 되었다. \n",
    "* room이나 maze에서는 물체가 랜덤하므로 환경의 belief를 추정하는데 중요 요소가 아니다(less significant)\n",
    "  * 그러므로 물체 예측을 잘 못하는 것이 오히려 당연\n",
    "* 만약 물체가 환경에서 중요한 역할을 하는 것으로 문제를 바꿔본다면\n",
    "  * belief는 좀 더 물체를 encoding하는데 집중할 것임\n",
    "* 이를 위해서 물체를 만나면 agent가 teleport하게 문제를 바꿔봄 \n",
    "  * teleport 문제의 경우 물체를 좀 더 중시할 것이고, 이는 물체 위치 예측의 정확도를 향상시킬 것으로 기대\n",
    "\n",
    "![](./images/beliefref/10.png)\n",
    "![](./images/beliefref/11.png)\n",
    "\n",
    "### RICHER UNCERTAINTY OVER POSITION\n",
    "\n",
    "* Toy GridWorld처럼 에이전트의 위치에 대한 불확실성을 더 명확히 하기 위한 문제 고안\n",
    "* 두개 복도 문제 \n",
    "  * 복도를 지나갈 때는 어떤 복도인지가 매우 불확실하나 복도 끝을 나와서 turning을 할 때면 어떤 복도인지 아주 명확해짐\n",
    "\n",
    "![](./images/beliefref/12.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
