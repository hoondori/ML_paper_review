{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossmodal Attentive Skill Learner\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threee Keywords : CrossModal, Attention, Options\n",
    "\n",
    "ex) audio-visual correspondence learning\n",
    "\n",
    "![](./images/its/02.png)\n",
    "\n",
    "![](./images/attentive_learner/01.png)\n",
    "\n",
    "![](./images/attentive_learner/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Crossmodal Attentive Skill Learner (CASL) ?\n",
    "\n",
    "* hierarchical reinforcement learning (HRL) useful \n",
    "  * when\n",
    "    * domains of high dimensionality\n",
    "    * tasks are durative but agents receive sparse feedback\n",
    "    * sensors compete for limited computational resource\n",
    "  * by\n",
    "    * focusing on problem decomposition for learning transferable skills\n",
    "* Options\n",
    "  * Temporal abstraction enables exploitation of domain regularities \n",
    "  * to provide the agent hierarchical guidance in the form of options or sub-goals\n",
    "  * by mitigating scalability issues in long-duration missions, by reducing the effective number of decision epochs.\n",
    "* Attention\n",
    "  * empowers the learner to focus on the most pertinent stimuli\n",
    "  * capture longer-term correlations in its encoded state\n",
    "\n",
    "* Our approach\n",
    "  * dimensionality reduction in time by options, in multi-sensory inputs by attentions\n",
    "  * focused on important inputs, efficient use of user's limited resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background setup\n",
    "\n",
    "![](./images/attentive_learner/03.png)\n",
    "\n",
    "![](./images/attentive_learner/04.png)\n",
    "\n",
    "![](./images/attentive_learner/05.png)\n",
    "\n",
    "![](./images/attentive_learner/06.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASL Architecture\n",
    "\n",
    "* crossmodal attention layer\n",
    "* The LSTM output captures temporal dependencies used to estimate option values, intra-option policies, and termination conditions\n",
    "* exogeneous attention over sensory features endogeneous attention over LSTM hidden state\n",
    "  * exogeneous : 자동적\n",
    "  * endogeneous : 자발적\n",
    "\n",
    "![](./images/attentive_learner/07.png)\n",
    "\n",
    "![](./images/attentive_learner/08.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "![](./images/attentive_learner/09.png)\n",
    "\n",
    "* 2D Minecraft-like domain\n",
    "  * mine의 종류에 따라 색상이 다르고, mine의 종류에 따라 곡괭이나 삽 중에 하나를 잘 골라서 광석 채굴 필요\n",
    "  * 입력 영상이 흑백으로 바뀌면 색상 힌트가 없으니 RL로 하면 잘 안됨 \n",
    "  * 소리가 mine의 종류마다 다르다고 하면, 소리가 추가적인 sensory input이 될 수 있다.\n",
    "  * mine과 멀 때는 잡음만 들리므로 소리는 별 도움안되고 영상이 도움이 많이 됨 \n",
    "  * mine에 가까우면 소리가 중요시됨 \n",
    "  * attention layer로 영상과 소리의 중요도를 자동적으로 파악하게..\n",
    "\n",
    "![](./images/attentive_learner/10.png)\n",
    "\n",
    "![](./images/attentive_learner/11.png)\n",
    "\n",
    "![](./images/attentive_learner/12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
